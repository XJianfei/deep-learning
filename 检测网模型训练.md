# 检测网模型训练-tensorflow

## 环境要求
python3.5   
ubuntu16.04   
JDK 1.8  
cuda9.0  
cudnn7.0  

Protobuf 3.0.0  
Python-tk  
Pillow 1.0  
lxml  
tf Slim (which is included in the "tensorflow/models/research/" checkout)  
Jupyter notebook  
Matplotlib  
Tensorflow (>=1.9.0)  
Cython  
contextlib2  
cocoapi  

## 环境配置
假设已经配置好了Ubuntu16.04+python3.5+cuda9.0+cudnn7.0环境，通过如下命令配置训练环境： 
创建一个全新的目录20181111，用户训练object detection 
>下载models源码：  
>cd 20181111  
>git clone https://github.com/tensorflow/models.git  
>git checkout 19d4eaaf5e1883776b341a4f704bb6a277e315aa -b objectdetection  

>安装TensorFlow：  
>pip3 install --force-reinstall tensorflow-gpu==1.9.0 --user  
  
>安装依赖包：  
>sudo apt-get install protobuf-compiler python3-pil python3-lxml python3-tk  
>pip3 install --user Cython  
>pip3 install --user contextlib2  
>pip3 install --user jupyter  
>pip3 install --user matplotlib  
>pip3 install --user opencv-python  

>安装COCO API：  
>cd 20181111  
>git clone https://github.com/cocodataset/cocoapi.git  
>git checkout ed842bffd41f6ff38707c4f0968d2cfd91088688 -b objectdetection  
>cd cocoapi/PythonAPI  
>修改Makefile文件：vim Makefile,将其中的python修改为python3  
>make  
>cp -r pycocotools < path_to_tensorflow >/models/research/  

>安装protobuf：  
>cd 20181111/models/research/  
>wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip  
>unzip protobuf.zip  
>./bin/protoc object_detection/protos/*.proto --python_out=.  

>配置slim  
>cd 20181111/models/research/
>export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim  

>测试环境配置  
>cd 20181111/models/research/  
>python3 object_detection/builders/model_builder_test.py  

## 准备数据
人脸检测数据使用开源数据集[wider face](http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/)  
下载一下三个数据包:  
![](https://i.imgur.com/Uc6NTm6.png)  
下载后的数据包名分别为：WIDER_train.zip WIDER_val.zip wider_face_split.zip  

下载数据转换脚本：  
>cd 20181111  
>git clone https://github.com/yeephycho/widerface-to-tfrecord.git  

准备存放数据目录：  
>cd 20181111/widerface-to-tfrecord  
>rm WIDER;mkdir WIDER  
>mkdir output  

拷贝下载好的WIDER_train.zip WIDER_val.zip wider_face_split.zip到WIDER目录下  
>cd 20181111/widerface-to-tfrecord/WIDER/  
>unzip WIDER_train.zip  
>unzip WIDER_val.zip  
>unzip wider_face_split.zip  
>cp wider_face_split/wider_face_train_bbx_gt.txt wider_face_train_annot.txt  
>cp wider_face_split/wider_face_val_bbx_gt.txt wider_face_val_annot.txt  

修改数据转换脚本(不修改在使用python3进行数据转换时会报错)  
>cd 20181111/widerface-to-tfrecord  
>vim widerface_To_TFRecord.py  
>修改：  
>43   encoded_image_data = open(filepath).read()为encoded_image_data = open(filepath,'rb').read()  
>61             classes_text.append('face')为classes_text.append(b'face')  
>75     'image/filename': dataset_util.bytes_feature(filename),为'image/filename': dataset_util.bytes_feature(filename.encode()),  
>76     'image/source_id': dataset_util.bytes_feature(filename),为'image/source_id': dataset_util.bytes_feature(filename.encode()),  

生成训练集TFRecord文件  
>cd 20181111/widerface-to-tfrecord  
>python3 widerface_To_TFRecord.py  

生成验证集TFRecord文件  
>cd 20181111/widerface-to-tfrecord  
>vim widerface_To_TFRecord.py  
>修改：  
>15、39、96行train为val  
>103行12880为3226  
>python3 widerface_To_TFRecord.py  

拷贝标签文件  
>cd 20181111/widerface-to-tfrecord  
>cp proto/face_label_map.pbtxt output/  

## 模型配置
创建原始模型存放目录  
>cd 20181111  
>mkdir origin_model  

下载模型  
>https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md  
>下载ssd_mobilenet_v1_coco模型文件ssd_mobilenet_v1_coco_2018_01_28.tar.gz存放到origin_model目录  
>tar zxvf ssd_mobilenet_v1_coco_2018_01_28.tar.gz  

配置pipeline.config文件  
>cd 20181111  
>vim origin_model/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config    
>修改：  
>3     num_classes: 90为num_classes: 1  
>157   fine_tune_checkpoint: "PATH_TO_BE_CONFIGURED/model.ckpt"为fine_tune_checkpoint: "/home/zack/20181019/origin_model/ssd_mobilenet_v1_coco_2018_01_28/model.ckpt"  
>162   label_map_path: "PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt"为label_map_path: "/home/zack/20181019/widerface-to-tfrecord/output/face_label_map.pbtxt"  
>164     input_path: "PATH_TO_BE_CONFIGURED/mscoco_train.record"为input_path: "/home/zack/20181019/widerface-to-tfrecord/output/train.tfrecord"  
>168   num_examples: 8000为num_examples: 3226  
>173   label_map_path: "PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt"为label_map_path: "/home/zack/20181019/widerface-to-tfrecord/output/face_label_map.pbtxt"  
>177     input_path: "PATH_TO_BE_CONFIGURED/mscoco_val.record"为/home/zack/20181019/widerface-to-tfrecord/output/val.tfrecord  

## 重训练模型
修改object_detection/metrics/coco_tools.py文件  
> cd 20181111/models/research/  
> vim object_detection/metrics/coco_tools.py  
> 将results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])修改为results.dataset['categories'] = copy.deepcopy(list(self.dataset['categories']))  
> 不然后再训练过程中会出现如下报错：  
> InvalidArgumentError (see above for traceback): TypeError: can't pickle dict_values objects  
>Traceback (most recent call last):  
>
>  File "/home/zack/.local/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py", line 158, in __call__  
>    ret = func(*args)  
>
>  File "/home/zack/20181019/models/research/object_detection/metrics/coco_evaluation.py", line 346, in first_value_func  
>    self._metrics = self.evaluate()  
>
>  File "/home/zack/20181019/models/research/object_detection/metrics/coco_evaluation.py", line 207, in evaluate  
>    self._detection_boxes_list)  
>
>  File "/home/zack/20181019/models/research/object_detection/metrics/coco_tools.py", line 118, in LoadAnnotations  
>    results.dataset['categories'] = copy.deepcopy(self.dataset['categories'])  
>
>  File "/usr/lib/python3.5/copy.py", line 174, in deepcopy  
>    rv = reductor(4)  
>
>TypeError: can't pickle dict_values objects  

训练模型  
>cd 20181111/models/research/  
>PIPELINE_CONFIG_PATH=/home/zack/20181019/origin_model/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config  
>train目录是用来存放训练过程文件以及最终模型文件的文件夹，在训练之前该文件夹需要为空文件夹，否则可能会出现“InvalidArgumentError(see above for trace back):Incompatible shapes:[2,1917] vs. [6,1]”，这是由于train目录下存在的checkpoint文件中num_classes与修改后的pipeline.config文件中的num_classes不匹配导致  
>MODEL_DIR=/home/zack/20181019/train  
>NUM_TRAIN_STEPS=200000  
>SAMPLE_1_OF_N_EVAL_EXAMPLES=1  
>python3 object_detection/model_main.py --pipeline_config_path=${PIPELINE_CONFIG_PATH} --model_dir=${MODEL_DIR} --num_train_steps=${NUM_TRAIN_STEPS} --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES --alsologtostderr  

训练完成后再/home/zack/20181019/train会生成model.ckpt-200000.data-00000-of-00001 model.ckpt-200000.index model.ckpt-200000.meta三个文件  

## 将模型转换为tflite文件
重命名最终模型  
>cd 20181019/train/  
>cp model.ckpt-200000.data-00000-of-00001 model.ckpt.data-00000-of-00001  
>cp model.ckpt-200000.index model.ckpt.index  
>cp model.ckpt-200000.meta model.ckpt.meta  

冻结模型  
>export CONFIG_FILE=/home/zack/20181019/origin_model/ssd_mobilenet_v1_coco_2018_01_28/pipeline.config  
>export CHECKPOINT_PATH=/home/zack/20181019/train/model.ckpt  
>mkdir /home/zack/20181019/output  
>export OUTPUT_DIR=/home/zack/20181019/output  
>cd 20181111/models/research/    
> “add_postprocessing_op参数决定冻结后的模型是否包含NMS（非极大抑制）层“  
>python3 object_detection/export_tflite_ssd_graph.py --pipeline_config_path=$CONFIG_FILE --trained_checkpoint_prefix=$CHECKPOINT_PATH --output_directory=$OUTPUT_DIR --add_postprocessing_op=true

转换为tflite模型文件  
>模型转换工具需要通过TensorFlow源码编译出来，所以一下命令均需要配置tensorflow源码编译环境，具体请参考：https://github.com/user-ZJ/Machine_learning_Fundamentals/blob/master/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE.md  
>量化模型转换  
>bazel run --config=opt tensorflow/contrib/lite/toco:toco -- \
--input_file=$OUTPUT_DIR/tflite_graph.pb \
--output_file=$OUTPUT_DIR/detect.tflite \
--input_shapes=1,300,300,3 \
--input_arrays=normalized_input_image_tensor \
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \
--inference_type=QUANTIZED_UINT8 \
--mean_values=128 \
--std_values=128 \
--change_concat_input_ranges=false \
--allow_custom_ops


>非量化模型转换  
>bazel run --config=opt tensorflow/contrib/lite/toco:toco \
--input_file=$OUTPUT_DIR/tflite_graph.pb \
--output_file=$OUTPUT_DIR/detect.tflite \
--input_shapes=1,300,300,3 \
--input_arrays=normalized_input_image_tensor \
--output_arrays='raw_outputs/class_predictions','raw_outputs/box_encodings' \
--inference_type=FLOAT \
--allow_custom_ops
--default_ranges_min=0   
--default_ranges_max=6






