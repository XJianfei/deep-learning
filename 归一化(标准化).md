# 归一化/标准化
数据标准化（归一化）处理是数据挖掘的一项基础工作，不同评价指标往往具有不同的量纲和量纲单位，这样的情况会影响到数据分析的结果，为了消除指标之间的量纲影响，需要进行数据标准化处理，以解决数据指标之间的可比性。原始数据经过数据标准化处理后，各指标处于同一数量级，适合进行综合对比评价。  
归一化防止直接对原始数据进行梯度下降类似的优化算法时最终解被数值大的特征所主导。  

## 归一化
对不同特征维度的伸缩变换的目的是使各个特征维度对目标函数的影响权重是一致的，即使得那些扁平分布的数据伸缩变换成类圆形。这也就改变了原始数据的一个分布。

好处：  
1 提高迭代求解的收敛速度  
2 提高迭代求解的精度

## 标准化
对不同特征维度的伸缩变换的目的是使得不同度量之间的特征具有可比性。同时不改变原始数据的分布。  

好处：  
1 使得不同度量之间的特征具有可比性，对目标函数的影响体现在几何分布上，而不是数值上  
2 不改变原始数据的分布  

## Standardization
Standardization又称为Z-score normalization，量化后的特征将服从标准正态分布（均值为0，标准差为1）：  
![](https://i.imgur.com/fc2muHM.png)  
其中，u和delta分别为对应特征的均值和标准差。量化后的特征将分布在[-1, 1]区间。  

## Min-Max Scaling
Min-Max Scaling又称为Min-Max normalization，也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0 - 1]之间。 特征量化的公式为：  
![](https://i.imgur.com/tFDBBbV.png)  
其中max为样本数据的最大值，min为样本数据的最小值。这种方法有个缺陷就是当有新数据加入时，可能导致max和min的变化，需要重新定义。  

大多数机器学习算法中，会选择Standardization来进行特征缩放，但是，Min-Max Scaling也并非会被弃置一地。在数字图像处理中，像素强度通常就会被量化到[0,1]区间，在一般的神经网络算法中，也会要求特征被量化[0，1]区间。  

参考：
https://www.zhihu.com/question/20467170  
https://blog.csdn.net/leiting_imecas/article/details/54986045  
https://blog.csdn.net/jacke121/article/details/79008333

